# Test Design: Epic 3 - Developer Workflow Integration & Tooling

**Date:** 2025-12-30
**Author:** Minh
**Status:** Draft

---

## Executive Summary

**Scope:** Full test design for Epic 3, focusing on CLI tools (`init`, `status`, `inspect`, `lint`) and daemon lifecycle management.

**Risk Summary:**

- Total risks identified: 7
- High-priority risks (≥6): 2
- Critical categories: OPS, BUS

**Coverage Summary:**

- P0 scenarios: 8 (16 hours)
- P1 scenarios: 12 (12 hours)
- P2/P3 scenarios: 10 (5 hours)
- **Total effort:** 33 hours (~4 days)

---

## Risk Assessment

### High-Priority Risks (Score ≥6)

| Risk ID | Category | Description | Probability | Impact | Score | Mitigation | Owner | Timeline |
| ------- | -------- | ----------- | ----------- | ------ | ----- | ---------- | ------- | -------- |
| R-301 | OPS | Daemon fails to start, stop, or persist (PID file sync issues, zombie processes) | 2 (Possible) | 3 (Critical) | 6 | Implement robust PID management with `psutil` checks and aggressive cleanup routines. | DEV | Sprint 3 |
| R-302 | BUS | `coretext lint` reports false positives, blocking developer commits and causing workflow friction | 3 (Likely) | 2 (Degraded) | 6 | Implement "Soft Fail" mode (warnings only) initially; add specific ignore flags/config. | DEV | Sprint 3 |

### Medium-Priority Risks (Score 3-4)

| Risk ID | Category | Description | Probability | Impact | Score | Mitigation | Owner |
| ------- | -------- | ----------- | ----------- | ------ | ----- | ---------- | ------- |
| R-303 | TECH | Dependency conflicts during `init` (SurrealDB binary, Nomic model download failures) | 2 | 2 | 4 | Vendor critical binaries or use robust retry logic with checksum validation. | DEV |
| R-304 | BUS | `coretext status` reports "Running" when daemon is unresponsive (zombie) | 2 | 2 | 4 | Status check must ping `/health` endpoint, not just check PID existence. | DEV |
| R-305 | PERF | `coretext lint` takes >5s on large repos, slowing down commit hooks | 2 | 2 | 4 | Implement incremental linting (check only changed files) by default. | DEV |
| R-306 | TECH | Templates generated by `coretext new` drift from actual graph schema | 2 | 2 | 4 | Add unit test ensuring templates parse validly against current schema. | QA |

### Low-Priority Risks (Score 1-2)

| Risk ID | Category | Description | Probability | Impact | Score | Action |
| ------- | -------- | ----------- | ----------- | ------ | ----- | ------- |
| R-307 | PERF | `inspect` command hangs on extremely deep dependency trees | 1 | 2 | 2 | Monitor / Add max-depth limit |

### Risk Category Legend

- **TECH**: Technical/Architecture (flaws, integration, scalability)
- **SEC**: Security (access controls, auth, data exposure)
- **PERF**: Performance (SLA violations, degradation, resource limits)
- **DATA**: Data Integrity (loss, corruption, inconsistency)
- **BUS**: Business Impact (UX harm, logic errors, revenue)
- **OPS**: Operations (deployment, config, monitoring)

---

## Test Coverage Plan

### P0 (Critical) - Run on every commit

**Criteria**: Blocks core journey + High risk (≥6) + No workaround

| Requirement | Test Level | Risk Link | Test Count | Owner | Notes |
| ----------- | ---------- | --------- | ---------- | ----- | ----- |
| Daemon Lifecycle (`init`, `start`) | E2E (CLI) | R-301 | 3 | QA | Verify PID creation, binary download, process startup |
| Daemon Lifecycle (`stop`) | E2E (CLI) | R-301 | 2 | QA | Verify graceful shutdown, PID cleanup |
| Lint Critical Errors | Integration | R-302 | 3 | DEV | Validate detection of malformed MD and broken links |

**Total P0**: 8 tests, 16 hours

### P1 (High) - Run on PR to main

**Criteria**: Important features + Medium risk (3-4) + Common workflows

| Requirement | Test Level | Risk Link | Test Count | Owner | Notes |
| ----------- | ---------- | --------- | ---------- | ----- | ----- |
| Status Health Check | Integration | R-304 | 3 | DEV | Mock zombie process, verify HTTP timeout handling |
| Inspect Dependency Tree | Integration | - | 4 | QA | Verify accurate tree output for known graph structures |
| Lint Performance | Unit | R-305 | 2 | DEV | Benchmark linting on 100+ file mock repo |
| Template Generation | Unit | R-306 | 3 | DEV | Verify generated files pass schema validation |

**Total P1**: 12 tests, 12 hours

### P2 (Medium) - Run nightly/weekly

**Criteria**: Secondary features + Low risk (1-2) + Edge cases

| Requirement | Test Level | Risk Link | Test Count | Owner | Notes |
| ----------- | ---------- | --------- | ---------- | ----- | ----- |
| CLI Output Formatting | Unit | - | 4 | DEV | Verify `Rich` table rendering and spinner behavior |
| Inspect Max Depth | Unit | R-307 | 2 | DEV | Verify recursion limits |
| Config Handling | Unit | - | 4 | DEV | Verify user config overrides defaults |

**Total P2**: 10 tests, 5 hours

### P3 (Low) - Run on-demand

**Criteria**: Nice-to-have + Exploratory + Performance benchmarks

*None planned for this iteration.*

---

## Execution Order

### Smoke Tests (<5 min)

**Purpose**: Fast feedback, catch build-breaking issues

- [ ] `coretext --version` returns version
- [ ] `coretext init` creates .coretext directory
- [ ] `coretext status` reports status correctly

**Total**: 3 scenarios

### P0 Tests (<10 min)

**Purpose**: Critical path validation

- [ ] Daemon `start` launches process and API is reachable
- [ ] Daemon `stop` terminates process and removes PID
- [ ] `coretext lint` fails on broken link (Red)
- [ ] `coretext lint` passes on valid repo (Green)

**Total**: 4 scenarios

### P1 Tests (<30 min)

**Purpose**: Important feature coverage

- [ ] `coretext inspect` output matches expected graph
- [ ] `coretext new prd` creates valid PRD file
- [ ] Status check identifies unresponsive daemon

**Total**: 3 scenarios

---

## Resource Estimates

### Test Development Effort

| Priority | Count | Hours/Test | Total Hours | Notes |
| -------- | ----- | ---------- | ----------- | ----- |
| P0 | 8 | 2.0 | 16 | Complex process management testing |
| P1 | 12 | 1.0 | 12 | Standard CLI interaction tests |
| P2 | 10 | 0.5 | 5 | Simple unit tests |
| **Total**| **30**| **-** | **33** | **~4 days** |

### Prerequisites

**Test Data:**

- **Mock Repos**: Set of fixture directories with valid/invalid Markdown for Lint/Init tests.
- **Mock Binary**: Fake `surreal` binary for testing download logic without network.

**Tooling:**

- `pytest-asyncio` for async daemon testing.
- `typer.testing.CliRunner` for CLI command testing.

**Environment:**

- Local filesystem access (sandbox safe).
- No external network required (mocked).

---

## Quality Gate Criteria

### Pass/Fail Thresholds

- **P0 pass rate**: 100% (no exceptions)
- **P1 pass rate**: ≥95% (waivers required for failures)
- **High-risk mitigations**: 100% complete or approved waivers

### Coverage Targets

- **CLI Commands**: ≥80%
- **Daemon Logic**: ≥90%

---

## Mitigation Plans

### R-301: Daemon Lifecycle Failure (Score: 6)

**Mitigation Strategy:** Use `psutil` to verify PID actually exists and corresponds to `coretext`. Implement "force kill" if graceful stop times out.
**Owner:** DEV
**Timeline:** Sprint 3
**Verification:** Test `stop` command with a hung process.

### R-302: Lint False Positives (Score: 6)

**Mitigation Strategy:** Default `lint` to "warn-only" mode for non-syntax errors (like style warnings). Hard fail only on syntax errors or broken links. Add `.coretextignore`.
**Owner:** DEV
**Timeline:** Sprint 3
**Verification:** Run lint on repo with known "ignored" style issues.

---

## Assumptions and Dependencies

### Assumptions

1. `surreal` binary is available for download or mocked.
2. User has write permissions to `~/.coretext` and project dir.

### Dependencies

1. `nomic` model download requires internet (mocked for tests).

---

## Follow-on Workflows (Manual)

- Run `*atdd` to generate failing P0 tests (separate workflow; not auto-run).

---

**Generated by**: BMad TEA Agent - Test Architect Module
**Workflow**: `_bmad/bmm/testarch/test-design`
